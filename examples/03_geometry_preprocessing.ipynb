{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1cdb5a5a",
   "metadata": {},
   "source": [
    "# Geometry Preprocessing with GMSHFlow\n",
    "\n",
    "This notebook focuses on GMSHFlow's geometry preprocessing capabilities, which are useful even without GMSH installation. These tools help prepare and clean geospatial data before mesh generation.\n",
    "\n",
    "Topics covered:\n",
    "1. Loading and cleaning geospatial data\n",
    "2. Geometry simplification while preserving topology\n",
    "3. Processing MultiLineStrings and complex geometries\n",
    "4. Data validation and quality checks\n",
    "5. Preparing data for mesh generation\n",
    "6. Integration with common GIS workflows\n",
    "\n",
    "**Note**: This example focuses on preprocessing utilities and doesn't require GMSH installation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016f5112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from shapely.geometry import Polygon, LineString, MultiLineString, Point, MultiPolygon\n",
    "from shapely.ops import unary_union\n",
    "import matplotlib.pyplot as plt\n",
    "import gmshflow\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(f\"GMSHFlow version: {gmshflow.__version__}\")\n",
    "print(\"Available preprocessing functions:\")\n",
    "preprocessing_funcs = [name for name in dir(gmshflow) if 'simplify' in name.lower() or 'merge' in name.lower()]\n",
    "for func in preprocessing_funcs:\n",
    "    print(f\"  - gmshflow.{func}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df71cb05",
   "metadata": {},
   "source": [
    "## Step 1: Create Complex Test Geometries\n",
    "\n",
    "Let's create some complex geometries that represent common challenges in geospatial data preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638a1622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a complex, high-resolution polygon (simulating detailed survey data)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create a detailed boundary with many vertices\n",
    "n_points = 200\n",
    "theta = np.linspace(0, 2*np.pi, n_points)\n",
    "base_radius = 500\n",
    "\n",
    "# Add multiple frequency components to create a complex shape\n",
    "noise = (50 * np.sin(5*theta) + \n",
    "         30 * np.sin(12*theta) + \n",
    "         20 * np.sin(25*theta) +\n",
    "         10 * np.random.randn(n_points))\n",
    "\n",
    "radius = base_radius + noise\n",
    "x_coords = 1000 + radius * np.cos(theta)\n",
    "y_coords = 500 + radius * np.sin(theta)\n",
    "\n",
    "# Create the detailed polygon\n",
    "detailed_coords = list(zip(x_coords, y_coords))\n",
    "detailed_polygon = Polygon(detailed_coords)\n",
    "\n",
    "# Create GeoDataFrame\n",
    "detailed_gdf = gpd.GeoDataFrame(\n",
    "    {'name': ['detailed_boundary'], 'type': ['survey_data']}, \n",
    "    geometry=[detailed_polygon]\n",
    ")\n",
    "\n",
    "print(f\"Original detailed polygon: {len(detailed_polygon.exterior.coords)} vertices\")\n",
    "print(f\"Area: {detailed_polygon.area:.0f} mÂ²\")\n",
    "print(f\"Perimeter: {detailed_polygon.length:.0f} m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311e6ccf",
   "metadata": {},
   "source": [
    "## Step 2: Create Complex LineString Data\n",
    "\n",
    "Create complex line data that might represent rivers, roads, or fault lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac88586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create multiple detailed LineStrings\n",
    "def create_detailed_line(start_point, end_point, n_points=50, noise_amplitude=20):\n",
    "    \"\"\"Create a detailed line with noise between two points.\"\"\"\n",
    "    t = np.linspace(0, 1, n_points)\n",
    "    \n",
    "    # Linear interpolation between start and end\n",
    "    x_base = start_point[0] + t * (end_point[0] - start_point[0])\n",
    "    y_base = start_point[1] + t * (end_point[1] - start_point[1])\n",
    "    \n",
    "    # Add noise perpendicular to the line direction\n",
    "    direction = np.array(end_point) - np.array(start_point)\n",
    "    perpendicular = np.array([-direction[1], direction[0]])\n",
    "    perpendicular = perpendicular / np.linalg.norm(perpendicular)\n",
    "    \n",
    "    noise = noise_amplitude * np.sin(10 * np.pi * t) * (1 + 0.5 * np.random.randn(n_points))\n",
    "    \n",
    "    x_coords = x_base + noise * perpendicular[0]\n",
    "    y_coords = y_base + noise * perpendicular[1]\n",
    "    \n",
    "    return LineString(zip(x_coords, y_coords))\n",
    "\n",
    "# Create several detailed LineStrings\n",
    "lines = [\n",
    "    create_detailed_line((400, 300), (1600, 700), n_points=80),  # Main river\n",
    "    create_detailed_line((600, 100), (1200, 900), n_points=60),  # Tributary 1\n",
    "    create_detailed_line((800, 200), (1400, 500), n_points=40),  # Tributary 2\n",
    "    create_detailed_line((500, 600), (1500, 400), n_points=70),  # Road\n",
    "]\n",
    "\n",
    "# Create a MultiLineString (common in GIS data)\n",
    "multi_linestring = MultiLineString(lines)\n",
    "\n",
    "# Create GeoDataFrame with mixed geometry types\n",
    "line_data = {\n",
    "    'name': ['main_river', 'tributary_1', 'tributary_2', 'road', 'multi_feature'],\n",
    "    'type': ['river', 'river', 'river', 'road', 'mixed'],\n",
    "    'priority': ['high', 'medium', 'medium', 'low', 'high']\n",
    "}\n",
    "\n",
    "geometries = lines + [multi_linestring]\n",
    "lines_gdf = gpd.GeoDataFrame(line_data, geometry=geometries)\n",
    "\n",
    "print(\"Created complex line geometries:\")\n",
    "for idx, row in lines_gdf.iterrows():\n",
    "    geom = row.geometry\n",
    "    if isinstance(geom, LineString):\n",
    "        vertex_count = len(geom.coords)\n",
    "    elif isinstance(geom, MultiLineString):\n",
    "        vertex_count = sum(len(line.coords) for line in geom.geoms)\n",
    "    else:\n",
    "        vertex_count = \"unknown\"\n",
    "    \n",
    "    print(f\"  {row['name']}: {type(geom).__name__}, {vertex_count} vertices\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97ac9c6",
   "metadata": {},
   "source": [
    "## Step 3: Visualize Original Complex Geometries\n",
    "\n",
    "Let's see what our complex, high-resolution data looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6334c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualization of original complex data\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Plot 1: Detailed polygon\n",
    "detailed_gdf.plot(ax=ax1, alpha=0.3, color='lightblue', edgecolor='blue', linewidth=1)\n",
    "ax1.set_title(f'Original Detailed Polygon\\n({len(detailed_polygon.exterior.coords)} vertices)')\n",
    "ax1.set_xlabel('X coordinate (m)')\n",
    "ax1.set_ylabel('Y coordinate (m)')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.set_aspect('equal')\n",
    "\n",
    "# Plot 2: Complex line data\n",
    "color_map = {'river': 'blue', 'road': 'red', 'mixed': 'purple'}\n",
    "for geom_type in ['river', 'road', 'mixed']:\n",
    "    subset = lines_gdf[lines_gdf['type'] == geom_type]\n",
    "    if len(subset) > 0:\n",
    "        subset.plot(ax=ax2, color=color_map[geom_type], linewidth=2, \n",
    "                   alpha=0.7, label=geom_type.title())\n",
    "\n",
    "ax2.set_title('Original Complex Line Data')\n",
    "ax2.set_xlabel('X coordinate (m)')\n",
    "ax2.set_ylabel('Y coordinate (m)')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.legend()\n",
    "ax2.set_aspect('equal')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Original data complexity:\")\n",
    "total_polygon_vertices = len(detailed_polygon.exterior.coords)\n",
    "total_line_vertices = sum(\n",
    "    len(geom.coords) if isinstance(geom, LineString) \n",
    "    else sum(len(line.coords) for line in geom.geoms)\n",
    "    for geom in lines_gdf.geometry\n",
    ")\n",
    "\n",
    "print(f\"  - Polygon vertices: {total_polygon_vertices}\")\n",
    "print(f\"  - Line vertices: {total_line_vertices}\")\n",
    "print(f\"  - Total vertices: {total_polygon_vertices + total_line_vertices}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88fb2e01",
   "metadata": {},
   "source": [
    "## Step 4: Apply Geometry Simplification\n",
    "\n",
    "Now let's use GMSHFlow's preprocessing functions to simplify the geometries while preserving their essential characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c697173f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different simplification tolerances\n",
    "tolerances = [5, 10, 25, 50]\n",
    "simplified_polygons = {}\n",
    "simplified_stats = {}\n",
    "\n",
    "print(\"Testing polygon simplification with different tolerances:\")\n",
    "print(f\"Original: {len(detailed_polygon.exterior.coords)} vertices\")\n",
    "\n",
    "for tolerance in tolerances:\n",
    "    # Use GMSHFlow's topology-preserving simplification\n",
    "    # Create a temporary GeoDataFrame with the tolerance as 'cs' column\n",
    "    temp_gdf = gpd.GeoDataFrame(\n",
    "        {'cs': [tolerance]}, \n",
    "        geometry=[detailed_polygon]\n",
    "    )\n",
    "    simplified_gdf = gmshflow.simplify_keeping_topology(temp_gdf,cs=tolerance)\n",
    "    simplified_geom = simplified_gdf.geometry.iloc[0]\n",
    "    \n",
    "    simplified_polygons[tolerance] = simplified_geom\n",
    "    \n",
    "    # Calculate statistics\n",
    "    original_vertices = len(detailed_polygon.exterior.coords)\n",
    "    simplified_vertices = len(simplified_geom.exterior.coords)\n",
    "    reduction = (1 - simplified_vertices / original_vertices) * 100\n",
    "    area_change = abs(simplified_geom.area - detailed_polygon.area) / detailed_polygon.area * 100\n",
    "    \n",
    "    simplified_stats[tolerance] = {\n",
    "        'vertices': simplified_vertices,\n",
    "        'reduction': reduction,\n",
    "        'area_change': area_change\n",
    "    }\n",
    "    \n",
    "    print(f\"  Tolerance {tolerance}m: {simplified_vertices} vertices \"\n",
    "          f\"({reduction:.1f}% reduction, {area_change:.2f}% area change)\")\n",
    "\n",
    "# Choose optimal tolerance (balance between simplification and quality)\n",
    "optimal_tolerance = 25  # Good balance for this example\n",
    "simplified_polygon = simplified_polygons[optimal_tolerance]\n",
    "simplified_polygon_gdf = gpd.GeoDataFrame(\n",
    "    {'name': ['simplified_boundary'], 'type': ['processed']}, \n",
    "    geometry=[simplified_polygon]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6adaba39",
   "metadata": {},
   "source": [
    "## Step 5: Process Complex LineString Data\n",
    "\n",
    "Now let's process the line data, including merging MultiLineStrings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f28b635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process MultiLineString data\n",
    "print(\"Processing MultiLineString data:\")\n",
    "\n",
    "# Find MultiLineString geometries\n",
    "multi_line_mask = lines_gdf.geometry.apply(lambda x: isinstance(x, MultiLineString))\n",
    "multi_lines = lines_gdf[multi_line_mask]\n",
    "\n",
    "print(f\"Found {len(multi_lines)} MultiLineString geometries\")\n",
    "\n",
    "# Process each MultiLineString\n",
    "processed_lines = []\n",
    "\n",
    "for idx, row in lines_gdf.iterrows():\n",
    "    geom = row.geometry\n",
    "    \n",
    "    if isinstance(geom, MultiLineString):\n",
    "        print(f\"\\nProcessing {row['name']} (MultiLineString with {len(geom.geoms)} parts):\")\n",
    "        \n",
    "        # Use GMSHFlow's function to merge MultiLineString into single LineString\n",
    "        try:\n",
    "            merged_line = gmshflow.merge_many_multilinestring_into_one_linestring([geom])\n",
    "            if merged_line and len(merged_line) > 0:\n",
    "                processed_geom = merged_line[0]  # Take the first (and should be only) result\n",
    "                print(f\"  Successfully merged into single LineString\")\n",
    "                print(f\"  Original parts: {len(geom.geoms)}\")\n",
    "                print(f\"  Merged vertices: {len(processed_geom.coords)}\")\n",
    "            else:\n",
    "                processed_geom = geom  # Keep original if merging fails\n",
    "                print(f\"  Merging failed, keeping original\")\n",
    "        except Exception as e:\n",
    "            print(f\"  Error during merging: {e}\")\n",
    "            processed_geom = geom  # Keep original on error\n",
    "    \n",
    "    elif isinstance(geom, LineString):\n",
    "        # Simplify regular LineStrings\n",
    "        original_vertices = len(geom.coords)\n",
    "        \n",
    "        # Create a temporary GeoDataFrame with the geometry and cs column\n",
    "        temp_gdf = gpd.GeoDataFrame(\n",
    "            {'cs': [10]}, \n",
    "            geometry=[geom]\n",
    "        )\n",
    "        simplified_gdf = gmshflow.simplify_keeping_topology(temp_gdf,cs=10)\n",
    "        processed_geom = simplified_gdf.geometry.iloc[0]\n",
    "        simplified_vertices = len(processed_geom.coords)\n",
    "        \n",
    "        print(f\"Simplified {row['name']}: {original_vertices} -> {simplified_vertices} vertices\")\n",
    "    \n",
    "    else:\n",
    "        processed_geom = geom  # Keep other geometry types as-is\n",
    "    \n",
    "    # Create processed row\n",
    "    processed_row = row.copy()\n",
    "    processed_row.geometry = processed_geom\n",
    "    processed_lines.append(processed_row)\n",
    "\n",
    "# Create processed lines GeoDataFrame\n",
    "processed_lines_gdf = gpd.GeoDataFrame(processed_lines)\n",
    "\n",
    "print(f\"\\nProcessing complete: {len(processed_lines_gdf)} geometries processed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2cb8fd",
   "metadata": {},
   "source": [
    "## Step 6: Visualize Before and After Comparison\n",
    "\n",
    "Let's create detailed comparisons showing the effect of our preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3548b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive before/after comparison\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Plot 1: Original polygon with vertex density visualization\n",
    "detailed_gdf.plot(ax=ax1, alpha=0.3, color='lightblue', edgecolor='blue', linewidth=2)\n",
    "# Show vertices as points for the boundary\n",
    "boundary_coords = np.array(detailed_polygon.exterior.coords)\n",
    "ax1.scatter(boundary_coords[:, 0], boundary_coords[:, 1], \n",
    "           c='red', s=1, alpha=0.5, label='Vertices')\n",
    "ax1.set_title(f'Original Polygon\\n{len(boundary_coords)} vertices')\n",
    "ax1.set_xlabel('X coordinate (m)')\n",
    "ax1.set_ylabel('Y coordinate (m)')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.legend()\n",
    "ax1.set_aspect('equal')\n",
    "\n",
    "# Plot 2: Simplified polygon\n",
    "simplified_polygon_gdf.plot(ax=ax2, alpha=0.3, color='lightgreen', edgecolor='green', linewidth=2)\n",
    "simplified_coords = np.array(simplified_polygon.exterior.coords)\n",
    "ax2.scatter(simplified_coords[:, 0], simplified_coords[:, 1], \n",
    "           c='red', s=3, alpha=0.8, label='Vertices')\n",
    "ax2.set_title(f'Simplified Polygon (tolerance={optimal_tolerance}m)\\n{len(simplified_coords)} vertices')\n",
    "ax2.set_xlabel('X coordinate (m)')\n",
    "ax2.set_ylabel('Y coordinate (m)')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.legend()\n",
    "ax2.set_aspect('equal')\n",
    "\n",
    "# Plot 3: Original lines with vertex density\n",
    "for geom_type in ['river', 'road', 'mixed']:\n",
    "    subset = lines_gdf[lines_gdf['type'] == geom_type]\n",
    "    if len(subset) > 0:\n",
    "        subset.plot(ax=ax3, color=color_map[geom_type], linewidth=3, \n",
    "                   alpha=0.7, label=f'Original {geom_type}')\n",
    "\n",
    "ax3.set_title('Original Line Data\\n(High vertex density)')\n",
    "ax3.set_xlabel('X coordinate (m)')\n",
    "ax3.set_ylabel('Y coordinate (m)')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "ax3.legend()\n",
    "ax3.set_aspect('equal')\n",
    "\n",
    "# Plot 4: Processed lines\n",
    "for geom_type in ['river', 'road', 'mixed']:\n",
    "    subset = processed_lines_gdf[processed_lines_gdf['type'] == geom_type]\n",
    "    if len(subset) > 0:\n",
    "        subset.plot(ax=ax4, color=color_map[geom_type], linewidth=3, \n",
    "                   alpha=0.7, label=f'Processed {geom_type}')\n",
    "\n",
    "ax4.set_title('Processed Line Data\\n(Simplified and merged)')\n",
    "ax4.set_xlabel('X coordinate (m)')\n",
    "ax4.set_ylabel('Y coordinate (m)')\n",
    "ax4.grid(True, alpha=0.3)\n",
    "ax4.legend()\n",
    "ax4.set_aspect('equal')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Create output directory and save\n",
    "output_dir = Path(\"./output\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "fig.savefig(output_dir / 'preprocessing_comparison.png', dpi=150, bbox_inches='tight')\n",
    "print(f\"Comparison plot saved to: {output_dir / 'preprocessing_comparison.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749d3f24",
   "metadata": {},
   "source": [
    "## Step 7: Quantitative Analysis and Quality Metrics\n",
    "\n",
    "Let's analyze the quantitative impact of our preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563cae2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive preprocessing analysis\n",
    "print(\"=== PREPROCESSING ANALYSIS ===\")\n",
    "\n",
    "# Polygon analysis\n",
    "print(\"\\n--- POLYGON SIMPLIFICATION ---\")\n",
    "original_poly_vertices = len(detailed_polygon.exterior.coords)\n",
    "simplified_poly_vertices = len(simplified_polygon.exterior.coords)\n",
    "poly_reduction = (1 - simplified_poly_vertices / original_poly_vertices) * 100\n",
    "area_preservation = (1 - abs(simplified_polygon.area - detailed_polygon.area) / detailed_polygon.area) * 100\n",
    "\n",
    "print(f\"Original vertices: {original_poly_vertices}\")\n",
    "print(f\"Simplified vertices: {simplified_poly_vertices}\")\n",
    "print(f\"Vertex reduction: {poly_reduction:.1f}%\")\n",
    "print(f\"Area preservation: {area_preservation:.2f}%\")\n",
    "print(f\"Simplification tolerance: {optimal_tolerance}m\")\n",
    "\n",
    "# Line analysis\n",
    "print(\"\\n--- LINE PROCESSING ---\")\n",
    "original_line_vertices = 0\n",
    "processed_line_vertices = 0\n",
    "multilinestring_count = 0\n",
    "merged_count = 0\n",
    "\n",
    "for orig_geom, proc_geom in zip(lines_gdf.geometry, processed_lines_gdf.geometry):\n",
    "    # Count original vertices\n",
    "    if isinstance(orig_geom, LineString):\n",
    "        original_line_vertices += len(orig_geom.coords)\n",
    "    elif isinstance(orig_geom, MultiLineString):\n",
    "        multilinestring_count += 1\n",
    "        original_line_vertices += sum(len(line.coords) for line in orig_geom.geoms)\n",
    "        if isinstance(proc_geom, LineString):  # Successfully merged\n",
    "            merged_count += 1\n",
    "    \n",
    "    # Count processed vertices\n",
    "    if isinstance(proc_geom, LineString):\n",
    "        processed_line_vertices += len(proc_geom.coords)\n",
    "    elif isinstance(proc_geom, MultiLineString):\n",
    "        processed_line_vertices += sum(len(line.coords) for line in proc_geom.geoms)\n",
    "\n",
    "line_reduction = (1 - processed_line_vertices / original_line_vertices) * 100\n",
    "\n",
    "print(f\"Original line vertices: {original_line_vertices}\")\n",
    "print(f\"Processed line vertices: {processed_line_vertices}\")\n",
    "print(f\"Line vertex reduction: {line_reduction:.1f}%\")\n",
    "print(f\"MultiLineStrings processed: {multilinestring_count}\")\n",
    "print(f\"Successfully merged: {merged_count}\")\n",
    "\n",
    "# Overall analysis\n",
    "print(\"\\n--- OVERALL IMPACT ---\")\n",
    "total_original = original_poly_vertices + original_line_vertices\n",
    "total_processed = simplified_poly_vertices + processed_line_vertices\n",
    "total_reduction = (1 - total_processed / total_original) * 100\n",
    "\n",
    "print(f\"Total original vertices: {total_original}\")\n",
    "print(f\"Total processed vertices: {total_processed}\")\n",
    "print(f\"Overall vertex reduction: {total_reduction:.1f}%\")\n",
    "\n",
    "# Create summary DataFrame\n",
    "summary_data = {\n",
    "    'Metric': [\n",
    "        'Polygon vertices (original)',\n",
    "        'Polygon vertices (simplified)',\n",
    "        'Line vertices (original)',\n",
    "        'Line vertices (processed)',\n",
    "        'Total vertices (original)',\n",
    "        'Total vertices (processed)',\n",
    "        'Polygon reduction (%)',\n",
    "        'Line reduction (%)',\n",
    "        'Overall reduction (%)',\n",
    "        'Area preservation (%)'\n",
    "    ],\n",
    "    'Value': [\n",
    "        original_poly_vertices,\n",
    "        simplified_poly_vertices,\n",
    "        original_line_vertices,\n",
    "        processed_line_vertices,\n",
    "        total_original,\n",
    "        total_processed,\n",
    "        f\"{poly_reduction:.1f}\",\n",
    "        f\"{line_reduction:.1f}\",\n",
    "        f\"{total_reduction:.1f}\",\n",
    "        f\"{area_preservation:.2f}\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "print(\"\\n--- SUMMARY TABLE ---\")\n",
    "print(summary_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5496a0",
   "metadata": {},
   "source": [
    "## Step 8: Export Processed Data\n",
    "\n",
    "Save the processed geometries for use in mesh generation or other applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e96537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export processed data\n",
    "print(\"Exporting processed geometries...\")\n",
    "\n",
    "# Save simplified polygon\n",
    "simplified_polygon_gdf.to_file(output_dir / 'simplified_polygon.shp')\n",
    "print(f\"Simplified polygon saved to: {output_dir / 'simplified_polygon.shp'}\")\n",
    "\n",
    "# Save processed lines\n",
    "processed_lines_gdf.to_file(output_dir / 'processed_lines.shp')\n",
    "print(f\"Processed lines saved to: {output_dir / 'processed_lines.shp'}\")\n",
    "\n",
    "# Save summary statistics\n",
    "summary_df.to_csv(output_dir / 'preprocessing_summary.csv', index=False)\n",
    "print(f\"Summary statistics saved to: {output_dir / 'preprocessing_summary.csv'}\")\n",
    "\n",
    "# Create a combined dataset ready for mesh generation\n",
    "print(\"\\nCreating mesh-ready dataset...\")\n",
    "\n",
    "# Combine all processed geometries\n",
    "mesh_ready_data = {\n",
    "    'geometry_type': ['domain'] + ['line'] * len(processed_lines_gdf),\n",
    "    'name': ['main_domain'] + processed_lines_gdf['name'].tolist(),\n",
    "    'mesh_priority': ['medium'] + processed_lines_gdf['priority'].tolist()\n",
    "}\n",
    "\n",
    "all_geometries = [simplified_polygon] + processed_lines_gdf.geometry.tolist()\n",
    "mesh_ready_gdf = gpd.GeoDataFrame(mesh_ready_data, geometry=all_geometries)\n",
    "\n",
    "# Add suggested mesh sizes based on geometry type and priority\n",
    "mesh_size_map = {\n",
    "    ('domain', 'medium'): 50,\n",
    "    ('line', 'high'): 20,\n",
    "    ('line', 'medium'): 30,\n",
    "    ('line', 'low'): 40\n",
    "}\n",
    "\n",
    "mesh_ready_gdf['suggested_mesh_size'] = [\n",
    "    mesh_size_map.get((row['geometry_type'], row['mesh_priority']), 50)\n",
    "    for _, row in mesh_ready_gdf.iterrows()\n",
    "]\n",
    "\n",
    "mesh_ready_gdf.to_file(output_dir / 'mesh_ready_geometries.gpkg', driver=\"GPKG\")\n",
    "print(f\"Mesh-ready dataset saved to: {output_dir / 'mesh_ready_geometries.gpkg'}\")\n",
    "\n",
    "print(f\"\\nMesh-ready dataset contains {len(mesh_ready_gdf)} geometries:\")\n",
    "for geom_type in mesh_ready_gdf['geometry_type'].unique():\n",
    "    count = len(mesh_ready_gdf[mesh_ready_gdf['geometry_type'] == geom_type])\n",
    "    print(f\"  - {geom_type}: {count} geometries\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a37a80",
   "metadata": {},
   "source": [
    "## Step 9: Validation and Quality Checks\n",
    "\n",
    "Perform validation checks on the processed geometries to ensure they're suitable for mesh generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9aa5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive validation of processed geometries\n",
    "print(\"=== GEOMETRY VALIDATION ===\")\n",
    "\n",
    "def validate_geometry(gdf, name):\n",
    "    \"\"\"Perform comprehensive validation on a GeoDataFrame.\"\"\"\n",
    "    print(f\"\\n--- {name.upper()} VALIDATION ---\")\n",
    "    \n",
    "    # Basic checks\n",
    "    print(f\"Number of geometries: {len(gdf)}\")\n",
    "    print(f\"CRS defined: {gdf.crs is not None}\")\n",
    "    \n",
    "    # Geometry validity\n",
    "    valid_geoms = gdf.geometry.is_valid.sum()\n",
    "    invalid_geoms = len(gdf) - valid_geoms\n",
    "    print(f\"Valid geometries: {valid_geoms}\")\n",
    "    print(f\"Invalid geometries: {invalid_geoms}\")\n",
    "    \n",
    "    if invalid_geoms > 0:\n",
    "        print(\"Warning: Invalid geometries detected!\")\n",
    "        invalid_idx = gdf[~gdf.geometry.is_valid].index\n",
    "        for idx in invalid_idx:\n",
    "            print(f\"  Invalid geometry at index {idx}: {gdf.loc[idx, 'name'] if 'name' in gdf.columns else 'unnamed'}\")\n",
    "    \n",
    "    # Geometry types\n",
    "    geom_types = gdf.geometry.geom_type.value_counts()\n",
    "    print(\"Geometry types:\")\n",
    "    for geom_type, count in geom_types.items():\n",
    "        print(f\"  - {geom_type}: {count}\")\n",
    "    \n",
    "    # Area/length statistics (where applicable)\n",
    "    if any(gdf.geometry.geom_type.isin(['Polygon', 'MultiPolygon'])):\n",
    "        polygon_mask = gdf.geometry.geom_type.isin(['Polygon', 'MultiPolygon'])\n",
    "        areas = gdf[polygon_mask].geometry.area\n",
    "        if len(areas) > 0:\n",
    "            print(f\"Polygon areas - Min: {areas.min():.0f}, Max: {areas.max():.0f}, Mean: {areas.mean():.0f}\")\n",
    "    \n",
    "    if any(gdf.geometry.geom_type.isin(['LineString', 'MultiLineString'])):\n",
    "        line_mask = gdf.geometry.geom_type.isin(['LineString', 'MultiLineString'])\n",
    "        lengths = gdf[line_mask].geometry.length\n",
    "        if len(lengths) > 0:\n",
    "            print(f\"Line lengths - Min: {lengths.min():.0f}, Max: {lengths.max():.0f}, Mean: {lengths.mean():.0f}\")\n",
    "    \n",
    "    # Check for empty geometries\n",
    "    empty_geoms = gdf.geometry.is_empty.sum()\n",
    "    if empty_geoms > 0:\n",
    "        print(f\"Warning: {empty_geoms} empty geometries detected!\")\n",
    "    \n",
    "    # Bounding box\n",
    "    bounds = gdf.total_bounds\n",
    "    print(f\"Bounding box: ({bounds[0]:.0f}, {bounds[1]:.0f}) to ({bounds[2]:.0f}, {bounds[3]:.0f})\")\n",
    "    \n",
    "    return valid_geoms == len(gdf) and empty_geoms == 0\n",
    "\n",
    "# Validate all processed datasets\n",
    "poly_valid = validate_geometry(simplified_polygon_gdf, \"Simplified Polygon\")\n",
    "lines_valid = validate_geometry(processed_lines_gdf, \"Processed Lines\")\n",
    "combined_valid = validate_geometry(mesh_ready_gdf, \"Mesh-Ready Dataset\")\n",
    "\n",
    "# Overall validation result\n",
    "print(\"\\n=== OVERALL VALIDATION RESULT ===\")\n",
    "all_valid = poly_valid and lines_valid and combined_valid\n",
    "\n",
    "if all_valid:\n",
    "    print(\"â ALL VALIDATIONS PASSED\")\n",
    "    print(\"Geometries are ready for mesh generation!\")\n",
    "else:\n",
    "    print(\"â VALIDATION ISSUES DETECTED\")\n",
    "    print(\"Please review and fix invalid geometries before mesh generation.\")\n",
    "\n",
    "# Mesh generation readiness checklist\n",
    "print(\"\\n=== MESH GENERATION READINESS ===\")\n",
    "checklist = {\n",
    "    \"All geometries are valid\": all_valid,\n",
    "    \"No empty geometries\": True,  # Checked in validation\n",
    "    \"Reasonable vertex count\": total_processed < 1000,  # Heuristic threshold\n",
    "    \"Geometries within reasonable bounds\": True,  # Could add specific checks\n",
    "    \"Domain polygon available\": len(simplified_polygon_gdf) > 0,\n",
    "    \"Suggested mesh sizes assigned\": 'suggested_mesh_size' in mesh_ready_gdf.columns\n",
    "}\n",
    "\n",
    "for check, passed in checklist.items():\n",
    "    status = \"â\" if passed else \"â\"\n",
    "    print(f\"{status} {check}\")\n",
    "\n",
    "mesh_ready = all(checklist.values())\n",
    "print(f\"\\nMesh generation readiness: {'â READY' if mesh_ready else 'â NOT READY'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729c4a32",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated GMSHFlow's powerful geometry preprocessing capabilities:\n",
    "\n",
    "### Key Preprocessing Functions Used:\n",
    "1. **`gmshflow.simplify_keeping_topology()`** - Reduces vertex count while preserving geometry shape and area\n",
    "2. **`gmshflow.merge_many_multilinestring_into_one_linestring()`** - Converts complex MultiLineString to simpler LineString\n",
    "\n",
    "### Benefits Achieved:\n",
    "- **Significant vertex reduction** while maintaining geometric accuracy\n",
    "- **Simplified data structures** easier to work with in mesh generation\n",
    "- **Quality validation** ensures data integrity before mesh generation\n",
    "- **Standardized formats** ready for GMSH processing\n",
    "\n",
    "### Real-World Applications:\n",
    "- **Survey Data Cleaning**: Simplify high-resolution GPS survey data\n",
    "- **GIS Data Preparation**: Process complex shapefiles for modeling\n",
    "- **CAD Data Integration**: Convert detailed CAD geometries for simulation\n",
    "- **Multi-Source Data**: Combine and clean data from different sources\n",
    "\n",
    "### Key Takeaways:\n",
    "1. **Topology preservation** is crucial - simple buffering/simplification can break geometries\n",
    "2. **Balance is important** - too much simplification loses important features\n",
    "3. **Validation is essential** - always check geometry validity after processing\n",
    "4. **Mesh sizing** should be planned during preprocessing, not after\n",
    "\n",
    "### Next Steps:\n",
    "- Use the processed geometries in mesh generation workflows\n",
    "- Experiment with different simplification tolerances for your data\n",
    "- Integrate preprocessing into automated data pipelines\n",
    "- Combine with other GIS tools for comprehensive workflows\n",
    "\n",
    "**Note**: These preprocessing tools work independently of GMSH, making them valuable for any geospatial data workflow, not just mesh generation!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gmshflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
